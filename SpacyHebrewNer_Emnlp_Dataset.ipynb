{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpacyHebrewNer-Emnlp Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH32hs4bNoj0IsATjrpAM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assafbz/HebrewNLP/blob/master/SpacyHebrewNer_Emnlp_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNHltCvEtVEU",
        "colab_type": "text"
      },
      "source": [
        "# Download EMNLP Dataset\n",
        "Downloaded from https://sites.google.com/site/rmyeid/projects/polylgot-ner \n",
        "Al-Rfou, Rami for Polyglot Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGjZpVUqkb80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5e4b8292-1659-4b32-b284-e8cd64cdbb8c"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = 'http://cs.stonybrook.edu/~polyglot/ner2/emnlp_datasets.tgz'\n",
        "wget.download(url)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=ad1e9fc79624275ffc0bdf7dd4a2158027a8ad977dac7aa20cfdfdff49eaea47\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'emnlp_datasets.tgz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ1AX2Nktsvl",
        "colab_type": "text"
      },
      "source": [
        "# Extract Data\n",
        "Only Hebrew Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwtcd442laWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2bf5908d-683d-4d39-82b8-e46df8b200e7"
      },
      "source": [
        "!tar -xvf emnlp_datasets.tgz acl_datasets/he"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acl_datasets/he/\n",
            "acl_datasets/he/data/\n",
            "acl_datasets/he/data/he_wiki.conll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhoyRl1FtynQ",
        "colab_type": "text"
      },
      "source": [
        "# Prepare train data for SpaCy\n",
        "note that text are rebuilt from tagged corpus cause no original texts were supplied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4qQycB-m-Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8cdf532-2580-4dcc-a33e-3ab777b482d7"
      },
      "source": [
        "train_data = []\n",
        "entities = []\n",
        "sentence = \"\"\n",
        "offset = 0\n",
        "with open('acl_datasets/he/data/he_wiki.conll', 'r') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      if line != '\\n':\n",
        "        token, tag = line.split('\\t')\n",
        "        tag = tag.rstrip()\n",
        "        if tag != 'O':\n",
        "          entity = (offset, offset + len(token), tag)\n",
        "          entities.append(entity)\n",
        "        sentence = sentence + token + ' '\n",
        "        offset += len(token) + 1\n",
        "\n",
        "      else:\n",
        "        train_data.append((sentence, {\"entities\": entities}))\n",
        "        entities = []\n",
        "        sentence = \"\"\n",
        "        offset = 0\n",
        "\n",
        "      if len(train_data) > 10000:\n",
        "        break;\n",
        "      line = f.readline()\n",
        "      \n",
        "print(\"Retrieved\", len(train_data), \"Samples\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 10001 Samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d20cnd0kt_FU",
        "colab_type": "text"
      },
      "source": [
        "# Check train data is correct and offsets are aligned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tRpnu9Gqgzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba36d240-de78-499e-8730-e787e51d1342"
      },
      "source": [
        "sample = train_data[2]\n",
        "for entity in sample[1][\"entities\"]:\n",
        "    print(sample[0][entity[0]:entity[1]], entity[2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "וורשה LOC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46_YasgYuFQb",
        "colab_type": "text"
      },
      "source": [
        "# Get Labels\n",
        "Keep only distinct labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiiVNLFBqvaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7667b32e-8cfc-4d10-ec06-32d307d97836"
      },
      "source": [
        "all_labels = []\n",
        "for doc in train_data:\n",
        "    for entity in doc[1]['entities']:\n",
        "        all_labels.append(entity[2])\n",
        "labels = list(set(all_labels))\n",
        "labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ORG', 'PER', 'LOC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfjns_pZuJjK",
        "colab_type": "text"
      },
      "source": [
        "# Build Spacy Hebrew Ner Model\n",
        "basic training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vlWbvBtrOYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64f978e3-8f5a-4151-aca3-6c4500f33032"
      },
      "source": [
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "from joblib import Parallel, delayed\n",
        "from functools import partial\n",
        "import random\n",
        "\n",
        "spacy.require_gpu()\n",
        "nlp = spacy.blank(\"he\")\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "nlp.add_pipe(ner, last=True)\n",
        "\n",
        "random.shuffle(train_data)\n",
        "for label in labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "optimizer = nlp.begin_training()  \n",
        "batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "losses = {}\n",
        "for batch in batches:\n",
        "    texts, annotations = zip(*batch)\n",
        "    nlp.update(\n",
        "        texts,  # batch of texts\n",
        "        annotations,  # batch of annotations\n",
        "        drop=0.5,  # dropout - make it harder to memorise data\n",
        "        losses=losses,\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n",
            "Another Batch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-32eddd7bacfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# batch of annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# dropout - make it harder to memorise data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin_update_scale_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(ops, X, mu, var)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__pow__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel._guess_routine\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel._guess_routine_from_in_types\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcan_cast\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G12ds_zUuOTD",
        "colab_type": "text"
      },
      "source": [
        "# Test On Train Data Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSZc8-3YrnB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a5f8ff97-e9fe-4a38-c0c9-37e2919b83e4"
      },
      "source": [
        "test_text = train_data[1][0]\n",
        "print(test_text)\n",
        "print('==========================')\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.label_, ent.text)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "בהמשך המלחמה נפצע לוין ושבר את שתי רגליו במהלך פעילות היחידה ב שדה התעופה פאיד שב מצרים , אף על פי כן לאחר חצי שנה בלבד פיקד על כוח היחידה שכבש את שיא החרמון ‏ . \n",
            "==========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy5J8fo8uR20",
        "colab_type": "text"
      },
      "source": [
        "# Test On New Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYFxSuYXrsoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98861eb0-b59f-4e91-b363-7e6da0330f4b"
      },
      "source": [
        "test_text = \"כבר שנים רבות שמשרד הבריאות אינו מאפשר לאזרחי ישראל לבצע פעילות בסיסית\"\n",
        "print(test_text)\n",
        "print('==========================')\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.label_, ent.text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "כבר שנים רבות שמשרד הבריאות אינו מאפשר לאזרחי ישראל לבצע פעילות בסיסית\n",
            "==========================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}