{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "SpacyHebrewNer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assafbz/HebrewNLP/blob/master/SpacyHebrewNer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrmZtavxexJ-",
        "colab_type": "text"
      },
      "source": [
        "# Download Tagged Corpus\n",
        "Downloaded from https://www.cs.bgu.ac.il/~elhadad/nlpproj/naama/ Naama Ben-Mordecai's MSc thesis and work on HebNer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoJPqatadFmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "abbba26d-7c3a-4a6b-d11a-8ecef2cf2b8e"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://www.cs.bgu.ac.il/~elhadad/nlpproj/naama/tagged_corpus.txt'\n",
        "wget.download(url)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=899e6a147e27cfc4e2dfaee8a84fc83a1181d72d88fac583b198fd653242fb38\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'tagged_corpus.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-AStXFKgPhS",
        "colab_type": "text"
      },
      "source": [
        "# Read and manipulate train data for SpaCy\n",
        "note that text are rebuilt from tagged corpus cause no original texts were supplied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iRLVI8gdFmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f033bcab-57a3-4c40-dd68-f2603c1443a2"
      },
      "source": [
        "train_data = []\n",
        "entities = []\n",
        "text = \"\"\n",
        "offset = 0\n",
        "is_first = True\n",
        "with open('tagged_corpus.txt', 'r') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        if line.startswith(\"--DOCSTART\") and is_first == False:\n",
        "            train_data.append((text, {\"entities\": entities}))\n",
        "            entities = []\n",
        "            text = \"\"\n",
        "            offset = 0\n",
        "        else:\n",
        "            vals = line.split(' ')\n",
        "            if len(vals) > 1:\n",
        "                token,tag = line.split(' ')\n",
        "                tag = tag.rstrip()\n",
        "                if tag != 'O':\n",
        "                    entity = (offset, offset + len(token), tag)\n",
        "                    entities.append(entity)\n",
        "                text = text + token + \" \"\n",
        "                offset += len(token) + 1\n",
        "        is_first = False\n",
        "        line = f.readline()\n",
        "        \n",
        "print(\"Retrieved\", len(train_data), \"Samples\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 189 Samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5UxXk3VgxZt",
        "colab_type": "text"
      },
      "source": [
        "# Check train data is correct and offsets are aligned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9igvc_tedFmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "eda2107b-a3c0-45c9-cba6-6008577915ac"
      },
      "source": [
        "sample = train_data[1]\n",
        "for entity in sample[1][\"entities\"]:\n",
        "    print(sample[0][entity[0]:entity[1]], entity[2])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ישראלים I_MISC__AFF\n",
            "14 I_PERCENT\n",
            "אחוז I_PERCENT\n",
            "3 I_PERCENT\n",
            "% I_PERCENT\n",
            "הישראליות I_MISC__AFF\n",
            "55 I_PERCENT\n",
            "% I_PERCENT\n",
            "מהישראליות I_MISC__AFF\n",
            "43 I_PERCENT\n",
            "% I_PERCENT\n",
            "קלוגס I_ORG\n",
            "חקר I_ORG\n",
            "רייטינג I_ORG\n",
            "6 I_PERCENT\n",
            "% I_PERCENT\n",
            "מהישראלים I_MISC__AFF\n",
            "1 I_PERCENT\n",
            "% I_PERCENT\n",
            "ואחוז I_PERCENT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W4tN6K8g6d0",
        "colab_type": "text"
      },
      "source": [
        "# Get Labels\n",
        "Keep only distinct labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvZgDpzkdFmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f0174661-6556-4601-ccd1-bb6317a15192"
      },
      "source": [
        "all_labels = []\n",
        "for doc in train_data:\n",
        "    for entity in doc[1]['entities']:\n",
        "        all_labels.append(entity[2])\n",
        "labels = list(set(all_labels))\n",
        "labels"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I_TIME',\n",
              " 'I_DATE',\n",
              " 'B_PERS',\n",
              " 'I_MONEY',\n",
              " 'I_PERS',\n",
              " 'I_MISC__ENT',\n",
              " 'I_MISC__AFF',\n",
              " 'B_LOC',\n",
              " 'B_DATE',\n",
              " 'I_LOC',\n",
              " 'B_MISC__AFF',\n",
              " 'B_TIME',\n",
              " 'I_PERCENT',\n",
              " 'I_ORG',\n",
              " 'B_ORG',\n",
              " 'B_MISC__ENT',\n",
              " 'I_MISC_EVENT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7BmFKPmhFT2",
        "colab_type": "text"
      },
      "source": [
        "# Build Spacy Hebrew Ner Model\n",
        "basic training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqU9Y6D6dFmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "spacy.require_gpu()\n",
        "nlp = spacy.blank(\"he\")\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "nlp.add_pipe(ner, last=True)\n",
        "\n",
        "random.shuffle(train_data)\n",
        "for label in labels:\n",
        "    ner.add_label(label)\n",
        "optimizer = nlp.begin_training()\n",
        "for text, annotations in train_data:\n",
        "    nlp.update([text], [annotations])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5eSK9SLhS0V",
        "colab_type": "text"
      },
      "source": [
        "# Test On Train Data Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEKG6mGRdFmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e52cb495-16a9-4f9d-d30a-43a5e40b020d"
      },
      "source": [
        "test_text = train_data[1][0]\n",
        "print(test_text)\n",
        "print('==========================')\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.label_, ent.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "גלישה נוספת של מי קולחין מטוהרים למימי מפרץ אילת גרמה אמש לזיהום המפרץ וליצירת כתם בוצה ענקי סמוך לגבול היבשתי עם ירדן . הדבר אירע לאחר שסוללות העפר , שהוקמו יממה קודם לכן , בכדי למנוע את גלישלת מי קולחין המטוהרים לים , קרסו והביאו לגלישת המים ממאגר אילת , לשטחים חקלאיים ולים . ממשרד הבריאות נמסר , כי מדובר במי קולחין ברמת מליחות גבוהה , שעברו טיהור ונמצא כי רמת חיידקי הקולי צואתי במים אלו נמוכה מהרגיל ואינה מסכנת בני אדם . מיד לאחר שהתגלה כתם הבוצה , הופסקה הזרמת מי הקולחין ממאגר אילת לים , והמים הוזרמו לתעלת הקינט ומשם לבריכות השיקוע של עיריית אילת הממוקמות בערבה . \n",
            "==========================\n",
            "I_LOC מפרץ\n",
            "I_LOC אילת\n",
            "I_ORG המפרץ\n",
            "I_LOC אילת\n",
            "I_ORG ממשרד\n",
            "I_ORG הבריאות\n",
            "I_LOC אילת\n",
            "I_ORG עיריית\n",
            "I_LOC בערבה\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYb9Tuf7hekd",
        "colab_type": "text"
      },
      "source": [
        "# Test On New Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1GalOlvhaTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "354c9102-04d1-40e6-cd0c-2087d19f5d34"
      },
      "source": [
        "test_text = \"כבר שנים רבות שמשרד הבריאות אינו מאפשר לאזרחי ישראל לבצע פעילות בסיסית\"\n",
        "print(test_text)\n",
        "print('==========================')\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.label_, ent.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "כבר שנים רבות שמשרד הבריאות אינו מאפשר לאזרחי ישראל לבצע פעילות בסיסית\n",
            "==========================\n",
            "I_LOC ישראל\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}